{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Introduction to Computer Vision\n",
    "\n",
    "Summer Semester 2022, 31.05.2022, Otto von Guericke University Magdeburg."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Exercise - Features 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we will again work with the [car racing](https://gym.openai.com/envs/CarRacing-v0/) environment from [Gym](http://gym.openai.com). Our goal is to apply different computer vision approaches to the simulator.\n",
    "\n",
    "The goal of this exercise is to generate different filter banks for texture extraction on the generated data. For this purpose, the generated images from the last assignment can be used. First, the **OpenCV** functions are used for the filter bank implementation. Then, the filter banks should be implemented without using the **OpenCV** package.\n",
    "\n",
    "\n",
    "*Important*: You need to install [Gym](http://gym.openai.com) in your system. The installation can be done with pip or by installing from the sources. More information at [https://gym.openai.com/docs/#installation](https://gym.openai.com/docs/#installation).\n",
    "\n",
    "The solutions for the assignment may be a Python Notebook or .py files. The visual results can be integrated into the notebook or a PDF document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A.  Scale-invariant feature transform (SIFT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, the SIFT algorithm should be developed for Car Racing images. It should be programmed from scratch, while the gradients can be extracted using the Sobel operator of **OpenCV**. All steps of SIFT will be programmed from the beginning, while NumPy or other python modules can be employed. It is required to implement the keypoint detection, descriptor extraction and finally perform matching between two consecutive images from the Car Racing demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from functools import cmp_to_key\n",
    "import logging\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "float_tolerance = 1e-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateBaseImage(image, sigma, assumed_blur):\n",
    "    \"\"\"Generate base image from input image by upsampling by 2 in both directions and blurring\n",
    "    \"\"\"\n",
    "    logger.debug('Generating base image...')\n",
    "    image = resize(image, (0, 0), fx=2, fy=2, interpolation=INTER_LINEAR)\n",
    "    sigma_diff = sqrt(max((sigma ** 2) - ((2 * assumed_blur) ** 2), 0.01))\n",
    "    return GaussianBlur(image, (0, 0), sigmaX=sigma_diff, sigmaY=sigma_diff)  # the image blur is now sigma instead of assumed_blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeNumberOfOctaves(image_shape):\n",
    "    \"\"\"Compute number of octaves in image pyramid as function of base image shape (OpenCV default)\n",
    "    \"\"\"\n",
    "    return int(round(log(min(image_shape)) / log(2) - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateGaussianKernels(sigma, num_intervals):\n",
    "    \"\"\"Generate list of gaussian kernels at which to blur the input image. Default values of sigma, intervals, and octaves follow section 3 of Lowe's paper.\n",
    "    \"\"\"\n",
    "    logger.debug('Generating scales...')\n",
    "    num_images_per_octave = num_intervals + 3\n",
    "    k = 2 ** (1. / num_intervals)\n",
    "    gaussian_kernels = zeros(num_images_per_octave)  # scale of gaussian blur necessary to go from one blur scale to the next within an octave\n",
    "    gaussian_kernels[0] = sigma\n",
    "    \n",
    "    for image_index in range(1, num_images_per_octave):\n",
    "        sigma_previous = (k ** (image_index - 1)) * sigma\n",
    "        sigma_total = k * sigma_previous\n",
    "        gaussian_kernels[image_index] = sqrt(sigma_total ** 2 - sigma_previous ** 2)\n",
    "    return gaussian_kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateGaussianImages(image, num_octaves, gaussian_kernels):\n",
    "    \"\"\"Generate scale-space pyramid of Gaussian images\n",
    "    \"\"\"\n",
    "    logger.debug('Generating Gaussian images...')\n",
    "    gaussian_images = []\n",
    "\n",
    "    for octave_index in range(num_octaves):\n",
    "        gaussian_images_in_octave = []\n",
    "        gaussian_images_in_octave.append(image)  # first image in octave already has the correct blur\n",
    "        for gaussian_kernel in gaussian_kernels[1:]:\n",
    "            image = GaussianBlur(image, (0, 0), sigmaX=gaussian_kernel, sigmaY=gaussian_kernel)\n",
    "            gaussian_images_in_octave.append(image)\n",
    "        gaussian_images.append(gaussian_images_in_octave)\n",
    "        octave_base = gaussian_images_in_octave[-3]\n",
    "        image = resize(octave_base, (int(octave_base.shape[1] / 2), int(octave_base.shape[0] / 2)), interpolation=INTER_NEAREST)\n",
    "    return array(gaussian_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateDoGImages(gaussian_images):\n",
    "    \"\"\"Generate Difference-of-Gaussians image pyramid\n",
    "    \"\"\"\n",
    "    logger.debug('Generating Difference-of-Gaussian images...')\n",
    "    dog_images = []\n",
    "\n",
    "    for gaussian_images_in_octave in gaussian_images:\n",
    "        dog_images_in_octave = []\n",
    "        for first_image, second_image in zip(gaussian_images_in_octave, gaussian_images_in_octave[1:]):\n",
    "            dog_images_in_octave.append(subtract(second_image, first_image))  # ordinary subtraction will not work because the images are unsigned integers\n",
    "        dog_images.append(dog_images_in_octave)\n",
    "    return array(dog_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findScaleSpaceExtrema(gaussian_images, dog_images, num_intervals, sigma, image_border_width, contrast_threshold=0.04):\n",
    "    \"\"\"Find pixel positions of all scale-space extrema in the image pyramid\n",
    "    \"\"\"\n",
    "    logger.debug('Finding scale-space extrema...')\n",
    "    threshold = floor(0.5 * contrast_threshold / num_intervals * 255)  # from OpenCV implementation\n",
    "    keypoints = []\n",
    "\n",
    "    for octave_index, dog_images_in_octave in enumerate(dog_images):\n",
    "        for image_index, (first_image, second_image, third_image) in enumerate(zip(dog_images_in_octave, dog_images_in_octave[1:], dog_images_in_octave[2:])):\n",
    "            # (i, j) is the center of the 3x3 array\n",
    "            for i in range(image_border_width, first_image.shape[0] - image_border_width):\n",
    "                for j in range(image_border_width, first_image.shape[1] - image_border_width):\n",
    "                    if isPixelAnExtremum(first_image[i-1:i+2, j-1:j+2], second_image[i-1:i+2, j-1:j+2], third_image[i-1:i+2, j-1:j+2], threshold):\n",
    "                        localization_result = localizeExtremumViaQuadraticFit(i, j, image_index + 1, octave_index, num_intervals, dog_images_in_octave, sigma, contrast_threshold, image_border_width)\n",
    "                        if localization_result is not None:\n",
    "                            keypoint, localized_image_index = localization_result\n",
    "                            keypoints_with_orientations = computeKeypointsWithOrientations(keypoint, octave_index, gaussian_images[octave_index][localized_image_index])\n",
    "                            for keypoint_with_orientation in keypoints_with_orientations:\n",
    "                                keypoints.append(keypoint_with_orientation)\n",
    "    return keypoints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isPixelAnExtremum(first_subimage, second_subimage, third_subimage, threshold):\n",
    "    \"\"\"Return True if the center element of the 3x3x3 input array is strictly greater than or less than all its neighbors, False otherwise\n",
    "    \"\"\"\n",
    "    center_pixel_value = second_subimage[1, 1]\n",
    "    if abs(center_pixel_value) > threshold:\n",
    "        if center_pixel_value > 0:\n",
    "            return all(center_pixel_value >= first_subimage) and \\\n",
    "                   all(center_pixel_value >= third_subimage) and \\\n",
    "                   all(center_pixel_value >= second_subimage[0, :]) and \\\n",
    "                   all(center_pixel_value >= second_subimage[2, :]) and \\\n",
    "                   center_pixel_value >= second_subimage[1, 0] and \\\n",
    "                   center_pixel_value >= second_subimage[1, 2]\n",
    "        elif center_pixel_value < 0:\n",
    "            return all(center_pixel_value <= first_subimage) and \\\n",
    "                   all(center_pixel_value <= third_subimage) and \\\n",
    "                   all(center_pixel_value <= second_subimage[0, :]) and \\\n",
    "                   all(center_pixel_value <= second_subimage[2, :]) and \\\n",
    "                   center_pixel_value <= second_subimage[1, 0] and \\\n",
    "                   center_pixel_value <= second_subimage[1, 2]\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def localizeExtremumViaQuadraticFit(i, j, image_index, octave_index, num_intervals, dog_images_in_octave, sigma, contrast_threshold, image_border_width, eigenvalue_ratio=10, num_attempts_until_convergence=5):\n",
    "    \"\"\"Iteratively refine pixel positions of scale-space extrema via quadratic fit around each extremum's neighbors\n",
    "    \"\"\"\n",
    "    logger.debug('Localizing scale-space extrema...')\n",
    "    extremum_is_outside_image = False\n",
    "    image_shape = dog_images_in_octave[0].shape\n",
    "    for attempt_index in range(num_attempts_until_convergence):\n",
    "        # need to convert from uint8 to float32 to compute derivatives and need to rescale pixel values to [0, 1] to apply Lowe's thresholds\n",
    "        first_image, second_image, third_image = dog_images_in_octave[image_index-1:image_index+2]\n",
    "        pixel_cube = stack([first_image[i-1:i+2, j-1:j+2],\n",
    "                            second_image[i-1:i+2, j-1:j+2],\n",
    "                            third_image[i-1:i+2, j-1:j+2]]).astype('float32') / 255.\n",
    "        gradient = computeGradientAtCenterPixel(pixel_cube)\n",
    "        hessian = computeHessianAtCenterPixel(pixel_cube)\n",
    "        extremum_update = -lstsq(hessian, gradient, rcond=None)[0]\n",
    "        if abs(extremum_update[0]) < 0.5 and abs(extremum_update[1]) < 0.5 and abs(extremum_update[2]) < 0.5:\n",
    "            break\n",
    "        j += int(round(extremum_update[0]))\n",
    "        i += int(round(extremum_update[1]))\n",
    "        image_index += int(round(extremum_update[2]))\n",
    "        # make sure the new pixel_cube will lie entirely within the image\n",
    "        if i < image_border_width or i >= image_shape[0] - image_border_width or j < image_border_width or j >= image_shape[1] - image_border_width or image_index < 1 or image_index > num_intervals:\n",
    "            extremum_is_outside_image = True\n",
    "            break\n",
    "    if extremum_is_outside_image:\n",
    "        logger.debug('Updated extremum moved outside of image before reaching convergence. Skipping...')\n",
    "        return None\n",
    "    if attempt_index >= num_attempts_until_convergence - 1:\n",
    "        logger.debug('Exceeded maximum number of attempts without reaching convergence for this extremum. Skipping...')\n",
    "        return None\n",
    "    functionValueAtUpdatedExtremum = pixel_cube[1, 1, 1] + 0.5 * dot(gradient, extremum_update)\n",
    "    if abs(functionValueAtUpdatedExtremum) * num_intervals >= contrast_threshold:\n",
    "        xy_hessian = hessian[:2, :2]\n",
    "        xy_hessian_trace = trace(xy_hessian)\n",
    "        xy_hessian_det = det(xy_hessian)\n",
    "        if xy_hessian_det > 0 and eigenvalue_ratio * (xy_hessian_trace ** 2) < ((eigenvalue_ratio + 1) ** 2) * xy_hessian_det:\n",
    "            # Contrast check passed -- construct and return OpenCV KeyPoint object\n",
    "            keypoint = KeyPoint()\n",
    "            keypoint.pt = ((j + extremum_update[0]) * (2 ** octave_index), (i + extremum_update[1]) * (2 ** octave_index))\n",
    "            keypoint.octave = octave_index + image_index * (2 ** 8) + int(round((extremum_update[2] + 0.5) * 255)) * (2 ** 16)\n",
    "            keypoint.size = sigma * (2 ** ((image_index + extremum_update[2]) / float32(num_intervals))) * (2 ** (octave_index + 1))  # octave_index + 1 because the input image was doubled\n",
    "            keypoint.response = abs(functionValueAtUpdatedExtremum)\n",
    "            return keypoint, image_index\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeGradientAtCenterPixel(pixel_array):\n",
    "    \"\"\"Approximate gradient at center pixel [1, 1, 1] of 3x3x3 array using central difference formula of order O(h^2), where h is the step size\n",
    "    \"\"\"\n",
    "    # With step size h, the central difference formula of order O(h^2) for f'(x) is (f(x + h) - f(x - h)) / (2 * h)\n",
    "    # Here h = 1, so the formula simplifies to f'(x) = (f(x + 1) - f(x - 1)) / 2\n",
    "    # NOTE: x corresponds to second array axis, y corresponds to first array axis, and s (scale) corresponds to third array axis\n",
    "    dx = 0.5 * (pixel_array[1, 1, 2] - pixel_array[1, 1, 0])\n",
    "    dy = 0.5 * (pixel_array[1, 2, 1] - pixel_array[1, 0, 1])\n",
    "    ds = 0.5 * (pixel_array[2, 1, 1] - pixel_array[0, 1, 1])\n",
    "    return array([dx, dy, ds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeHessianAtCenterPixel(pixel_array):\n",
    "    \"\"\"Approximate Hessian at center pixel [1, 1, 1] of 3x3x3 array using central difference formula of order O(h^2), where h is the step size\n",
    "    \"\"\"\n",
    "    # With step size h, the central difference formula of order O(h^2) for f''(x) is (f(x + h) - 2 * f(x) + f(x - h)) / (h ^ 2)\n",
    "    # Here h = 1, so the formula simplifies to f''(x) = f(x + 1) - 2 * f(x) + f(x - 1)\n",
    "    # With step size h, the central difference formula of order O(h^2) for (d^2) f(x, y) / (dx dy) = (f(x + h, y + h) - f(x + h, y - h) - f(x - h, y + h) + f(x - h, y - h)) / (4 * h ^ 2)\n",
    "    # Here h = 1, so the formula simplifies to (d^2) f(x, y) / (dx dy) = (f(x + 1, y + 1) - f(x + 1, y - 1) - f(x - 1, y + 1) + f(x - 1, y - 1)) / 4\n",
    "    # NOTE: x corresponds to second array axis, y corresponds to first array axis, and s (scale) corresponds to third array axis\n",
    "    center_pixel_value = pixel_array[1, 1, 1]\n",
    "    dxx = pixel_array[1, 1, 2] - 2 * center_pixel_value + pixel_array[1, 1, 0]\n",
    "    dyy = pixel_array[1, 2, 1] - 2 * center_pixel_value + pixel_array[1, 0, 1]\n",
    "    dss = pixel_array[2, 1, 1] - 2 * center_pixel_value + pixel_array[0, 1, 1]\n",
    "    dxy = 0.25 * (pixel_array[1, 2, 2] - pixel_array[1, 2, 0] - pixel_array[1, 0, 2] + pixel_array[1, 0, 0])\n",
    "    dxs = 0.25 * (pixel_array[2, 1, 2] - pixel_array[2, 1, 0] - pixel_array[0, 1, 2] + pixel_array[0, 1, 0])\n",
    "    dys = 0.25 * (pixel_array[2, 2, 1] - pixel_array[2, 0, 1] - pixel_array[0, 2, 1] + pixel_array[0, 0, 1])\n",
    "    return array([[dxx, dxy, dxs], \n",
    "                  [dxy, dyy, dys],\n",
    "                  [dxs, dys, dss]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeKeypointsWithOrientations(keypoint, octave_index, gaussian_image, radius_factor=3, num_bins=36, peak_ratio=0.8, scale_factor=1.5):\n",
    "    \"\"\"Compute orientations for each keypoint\n",
    "    \"\"\"\n",
    "    logger.debug('Computing keypoint orientations...')\n",
    "    keypoints_with_orientations = []\n",
    "    image_shape = gaussian_image.shape\n",
    "\n",
    "    scale = scale_factor * keypoint.size / float32(2 ** (octave_index + 1))  # compare with keypoint.size computation in localizeExtremumViaQuadraticFit()\n",
    "    radius = int(round(radius_factor * scale))\n",
    "    weight_factor = -0.5 / (scale ** 2)\n",
    "    raw_histogram = zeros(num_bins)\n",
    "    smooth_histogram = zeros(num_bins)\n",
    "\n",
    "    for i in range(-radius, radius + 1):\n",
    "        region_y = int(round(keypoint.pt[1] / float32(2 ** octave_index))) + i\n",
    "        if region_y > 0 and region_y < image_shape[0] - 1:\n",
    "            for j in range(-radius, radius + 1):\n",
    "                region_x = int(round(keypoint.pt[0] / float32(2 ** octave_index))) + j\n",
    "                if region_x > 0 and region_x < image_shape[1] - 1:\n",
    "                    dx = gaussian_image[region_y, region_x + 1] - gaussian_image[region_y, region_x - 1]\n",
    "                    dy = gaussian_image[region_y - 1, region_x] - gaussian_image[region_y + 1, region_x]\n",
    "                    gradient_magnitude = sqrt(dx * dx + dy * dy)\n",
    "                    gradient_orientation = rad2deg(arctan2(dy, dx))\n",
    "                    weight = exp(weight_factor * (i ** 2 + j ** 2))  # constant in front of exponential can be dropped because we will find peaks later\n",
    "                    histogram_index = int(round(gradient_orientation * num_bins / 360.))\n",
    "                    raw_histogram[histogram_index % num_bins] += weight * gradient_magnitude\n",
    "\n",
    "    for n in range(num_bins):\n",
    "        smooth_histogram[n] = (6 * raw_histogram[n] + 4 * (raw_histogram[n - 1] + raw_histogram[(n + 1) % num_bins]) + raw_histogram[n - 2] + raw_histogram[(n + 2) % num_bins]) / 16.\n",
    "    orientation_max = max(smooth_histogram)\n",
    "    orientation_peaks = where(logical_and(smooth_histogram > roll(smooth_histogram, 1), smooth_histogram > roll(smooth_histogram, -1)))[0]\n",
    "    for peak_index in orientation_peaks:\n",
    "        peak_value = smooth_histogram[peak_index]\n",
    "        if peak_value >= peak_ratio * orientation_max:\n",
    "            # Quadratic peak interpolation\n",
    "            # The interpolation update is given by equation (6.30) in https://ccrma.stanford.edu/~jos/sasp/Quadratic_Interpolation_Spectral_Peaks.html\n",
    "            left_value = smooth_histogram[(peak_index - 1) % num_bins]\n",
    "            right_value = smooth_histogram[(peak_index + 1) % num_bins]\n",
    "            interpolated_peak_index = (peak_index + 0.5 * (left_value - right_value) / (left_value - 2 * peak_value + right_value)) % num_bins\n",
    "            orientation = 360. - interpolated_peak_index * 360. / num_bins\n",
    "            if abs(orientation - 360.) < float_tolerance:\n",
    "                orientation = 0\n",
    "            new_keypoint = KeyPoint(*keypoint.pt, keypoint.size, orientation, keypoint.response, keypoint.octave)\n",
    "            keypoints_with_orientations.append(new_keypoint)\n",
    "    return keypoints_with_orientations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compareKeypoints(keypoint1, keypoint2):\n",
    "    \"\"\"Return True if keypoint1 is less than keypoint2\n",
    "    \"\"\"\n",
    "    if keypoint1.pt[0] != keypoint2.pt[0]:\n",
    "        return keypoint1.pt[0] - keypoint2.pt[0]\n",
    "    if keypoint1.pt[1] != keypoint2.pt[1]:\n",
    "        return keypoint1.pt[1] - keypoint2.pt[1]\n",
    "    if keypoint1.size != keypoint2.size:\n",
    "        return keypoint2.size - keypoint1.size\n",
    "    if keypoint1.angle != keypoint2.angle:\n",
    "        return keypoint1.angle - keypoint2.angle\n",
    "    if keypoint1.response != keypoint2.response:\n",
    "        return keypoint2.response - keypoint1.response\n",
    "    if keypoint1.octave != keypoint2.octave:\n",
    "        return keypoint2.octave - keypoint1.octave\n",
    "    return keypoint2.class_id - keypoint1.class_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeDuplicateKeypoints(keypoints):\n",
    "    \"\"\"Sort keypoints and remove duplicate keypoints\n",
    "    \"\"\"\n",
    "    if len(keypoints) < 2:\n",
    "        return keypoints\n",
    "\n",
    "    keypoints.sort(key=cmp_to_key(compareKeypoints))\n",
    "    unique_keypoints = [keypoints[0]]\n",
    "\n",
    "    for next_keypoint in keypoints[1:]:\n",
    "        last_unique_keypoint = unique_keypoints[-1]\n",
    "        if last_unique_keypoint.pt[0] != next_keypoint.pt[0] or \\\n",
    "           last_unique_keypoint.pt[1] != next_keypoint.pt[1] or \\\n",
    "           last_unique_keypoint.size != next_keypoint.size or \\\n",
    "           last_unique_keypoint.angle != next_keypoint.angle:\n",
    "            unique_keypoints.append(next_keypoint)\n",
    "    return unique_keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertKeypointsToInputImageSize(keypoints):\n",
    "    \"\"\"Convert keypoint point, size, and octave to input image size\n",
    "    \"\"\"\n",
    "    converted_keypoints = []\n",
    "    for keypoint in keypoints:\n",
    "        keypoint.pt = tuple(0.5 * array(keypoint.pt))\n",
    "        keypoint.size *= 0.5\n",
    "        keypoint.octave = (keypoint.octave & ~255) | ((keypoint.octave - 1) & 255)\n",
    "        converted_keypoints.append(keypoint)\n",
    "    return converted_keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpackOctave(keypoint):\n",
    "    \"\"\"Compute octave, layer, and scale from a keypoint\n",
    "    \"\"\"\n",
    "    octave = keypoint.octave & 255\n",
    "    layer = (keypoint.octave >> 8) & 255\n",
    "    if octave >= 128:\n",
    "        octave = octave | -128\n",
    "    scale = 1 / float32(1 << octave) if octave >= 0 else float32(1 << -octave)\n",
    "    return octave, layer, scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateDescriptors(keypoints, gaussian_images, window_width=4, num_bins=8, scale_multiplier=3, descriptor_max_value=0.2):\n",
    "    \"\"\"Generate descriptors for each keypoint\n",
    "    \"\"\"\n",
    "    logger.debug('Generating descriptors...')\n",
    "    descriptors = []\n",
    "\n",
    "    for keypoint in keypoints:\n",
    "        octave, layer, scale = unpackOctave(keypoint)\n",
    "        gaussian_image = gaussian_images[octave + 1, layer]\n",
    "        num_rows, num_cols = gaussian_image.shape\n",
    "        point = round(scale * array(keypoint.pt)).astype('int')\n",
    "        bins_per_degree = num_bins / 360.\n",
    "        angle = 360. - keypoint.angle\n",
    "        cos_angle = cos(deg2rad(angle))\n",
    "        sin_angle = sin(deg2rad(angle))\n",
    "        weight_multiplier = -0.5 / ((0.5 * window_width) ** 2)\n",
    "        row_bin_list = []\n",
    "        col_bin_list = []\n",
    "        magnitude_list = []\n",
    "        orientation_bin_list = []\n",
    "        histogram_tensor = zeros((window_width + 2, window_width + 2, num_bins))   # first two dimensions are increased by 2 to account for border effects\n",
    "\n",
    "        # Descriptor window size (described by half_width) follows OpenCV convention\n",
    "        hist_width = scale_multiplier * 0.5 * scale * keypoint.size\n",
    "        half_width = int(round(hist_width * sqrt(2) * (window_width + 1) * 0.5))   # sqrt(2) corresponds to diagonal length of a pixel\n",
    "        half_width = int(min(half_width, sqrt(num_rows ** 2 + num_cols ** 2)))     # ensure half_width lies within image\n",
    "\n",
    "        for row in range(-half_width, half_width + 1):\n",
    "            for col in range(-half_width, half_width + 1):\n",
    "                row_rot = col * sin_angle + row * cos_angle\n",
    "                col_rot = col * cos_angle - row * sin_angle\n",
    "                row_bin = (row_rot / hist_width) + 0.5 * window_width - 0.5\n",
    "                col_bin = (col_rot / hist_width) + 0.5 * window_width - 0.5\n",
    "                if row_bin > -1 and row_bin < window_width and col_bin > -1 and col_bin < window_width:\n",
    "                    window_row = int(round(point[1] + row))\n",
    "                    window_col = int(round(point[0] + col))\n",
    "                    if window_row > 0 and window_row < num_rows - 1 and window_col > 0 and window_col < num_cols - 1:\n",
    "                        dx = gaussian_image[window_row, window_col + 1] - gaussian_image[window_row, window_col - 1]\n",
    "                        dy = gaussian_image[window_row - 1, window_col] - gaussian_image[window_row + 1, window_col]\n",
    "                        gradient_magnitude = sqrt(dx * dx + dy * dy)\n",
    "                        gradient_orientation = rad2deg(arctan2(dy, dx)) % 360\n",
    "                        weight = exp(weight_multiplier * ((row_rot / hist_width) ** 2 + (col_rot / hist_width) ** 2))\n",
    "                        row_bin_list.append(row_bin)\n",
    "                        col_bin_list.append(col_bin)\n",
    "                        magnitude_list.append(weight * gradient_magnitude)\n",
    "                        orientation_bin_list.append((gradient_orientation - angle) * bins_per_degree)\n",
    "\n",
    "        for row_bin, col_bin, magnitude, orientation_bin in zip(row_bin_list, col_bin_list, magnitude_list, orientation_bin_list):\n",
    "            # Smoothing via trilinear interpolation\n",
    "            # Notations follows https://en.wikipedia.org/wiki/Trilinear_interpolation\n",
    "            # Note that we are really doing the inverse of trilinear interpolation here (we take the center value of the cube and distribute it among its eight neighbors)\n",
    "            row_bin_floor, col_bin_floor, orientation_bin_floor = floor([row_bin, col_bin, orientation_bin]).astype(int)\n",
    "            row_fraction, col_fraction, orientation_fraction = row_bin - row_bin_floor, col_bin - col_bin_floor, orientation_bin - orientation_bin_floor\n",
    "            if orientation_bin_floor < 0:\n",
    "                orientation_bin_floor += num_bins\n",
    "            if orientation_bin_floor >= num_bins:\n",
    "                orientation_bin_floor -= num_bins\n",
    "\n",
    "            c1 = magnitude * row_fraction\n",
    "            c0 = magnitude * (1 - row_fraction)\n",
    "            c11 = c1 * col_fraction\n",
    "            c10 = c1 * (1 - col_fraction)\n",
    "            c01 = c0 * col_fraction\n",
    "            c00 = c0 * (1 - col_fraction)\n",
    "            c111 = c11 * orientation_fraction\n",
    "            c110 = c11 * (1 - orientation_fraction)\n",
    "            c101 = c10 * orientation_fraction\n",
    "            c100 = c10 * (1 - orientation_fraction)\n",
    "            c011 = c01 * orientation_fraction\n",
    "            c010 = c01 * (1 - orientation_fraction)\n",
    "            c001 = c00 * orientation_fraction\n",
    "            c000 = c00 * (1 - orientation_fraction)\n",
    "\n",
    "            histogram_tensor[row_bin_floor + 1, col_bin_floor + 1, orientation_bin_floor] += c000\n",
    "            histogram_tensor[row_bin_floor + 1, col_bin_floor + 1, (orientation_bin_floor + 1) % num_bins] += c001\n",
    "            histogram_tensor[row_bin_floor + 1, col_bin_floor + 2, orientation_bin_floor] += c010\n",
    "            histogram_tensor[row_bin_floor + 1, col_bin_floor + 2, (orientation_bin_floor + 1) % num_bins] += c011\n",
    "            histogram_tensor[row_bin_floor + 2, col_bin_floor + 1, orientation_bin_floor] += c100\n",
    "            histogram_tensor[row_bin_floor + 2, col_bin_floor + 1, (orientation_bin_floor + 1) % num_bins] += c101\n",
    "            histogram_tensor[row_bin_floor + 2, col_bin_floor + 2, orientation_bin_floor] += c110\n",
    "            histogram_tensor[row_bin_floor + 2, col_bin_floor + 2, (orientation_bin_floor + 1) % num_bins] += c111\n",
    "\n",
    "        descriptor_vector = histogram_tensor[1:-1, 1:-1, :].flatten()  # Remove histogram borders\n",
    "        # Threshold and normalize descriptor_vector\n",
    "        threshold = norm(descriptor_vector) * descriptor_max_value\n",
    "        descriptor_vector[descriptor_vector > threshold] = threshold\n",
    "        descriptor_vector /= max(norm(descriptor_vector), float_tolerance)\n",
    "        # Multiply by 512, round, and saturate between 0 and 255 to convert from float32 to unsigned char (OpenCV convention)\n",
    "        descriptor_vector = round(512 * descriptor_vector)\n",
    "        descriptor_vector[descriptor_vector < 0] = 0\n",
    "        descriptor_vector[descriptor_vector > 255] = 255\n",
    "        descriptors.append(descriptor_vector)\n",
    "    return array(descriptors, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cv2 import resize, GaussianBlur, subtract, KeyPoint, INTER_LINEAR, INTER_NEAREST\n",
    "from numpy import all, any, array, arctan2, cos, sin, exp, dot, log, logical_and, roll, sqrt, stack, trace, unravel_index, pi, deg2rad, rad2deg, where, zeros, floor, full, nan, isnan, round, float32\n",
    "from numpy.linalg import det, lstsq, norm\n",
    "\n",
    "def computeKeypointsAndDescriptors(image, sigma=1.6, num_intervals=3, assumed_blur=0.5, image_border_width=5):\n",
    "    \"\"\"Compute SIFT keypoints and descriptors for an input image\n",
    "    \"\"\"\n",
    "    image = image.astype('float32')\n",
    "    base_image = generateBaseImage(image, sigma, assumed_blur)\n",
    "    num_octaves = computeNumberOfOctaves(base_image.shape)\n",
    "    gaussian_kernels = generateGaussianKernels(sigma, num_intervals)\n",
    "    gaussian_images = generateGaussianImages(base_image, num_octaves, gaussian_kernels)\n",
    "    dog_images = generateDoGImages(gaussian_images)\n",
    "    keypoints = findScaleSpaceExtrema(gaussian_images, dog_images, num_intervals, sigma, image_border_width)\n",
    "    keypoints = removeDuplicateKeypoints(keypoints)\n",
    "    keypoints = convertKeypointsToInputImageSize(keypoints)\n",
    "    descriptors = generateDescriptors(keypoints, gaussian_images)\n",
    "    return keypoints, descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_MATCH_COUNT = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread(r\"G://OVGU Study//Sem2//Introduction to Computer Vision//Assignments//assign1//image.png\", 0)           # queryImage\n",
    "img2 = cv2.imread(r\"G://OVGU Study//Sem2//Introduction to Computer Vision//Assignments//assign1//image_test.png\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-1b7ace61cdf2>:16: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(gaussian_images)\n",
      "<ipython-input-9-db40b98a6bc8>:12: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(dog_images)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "kp1, des1 = computeKeypointsAndDescriptors(img1)\n",
    "kp2, des2 = computeKeypointsAndDescriptors(img2)\n",
    "\n",
    "FLANN_INDEX_KDTREE = 0\n",
    "index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "search_params = dict(checks = 50)\n",
    "flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "matches = flann.knnMatch(des1, des2, k=2)\n",
    "\n",
    "good = []\n",
    "for m, n in matches:\n",
    "    if m.distance < 0.7 * n.distance:\n",
    "        good.append(m)\n",
    "\n",
    "if len(good) > MIN_MATCH_COUNT:\n",
    "    # Estimate homography between template and scene\n",
    "    src_pts = np.float32([ kp1[m.queryIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "    dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "\n",
    "    M = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)[0]\n",
    "\n",
    "    # Draw detected template in scene image\n",
    "    h, w = img1.shape\n",
    "    pts = np.float32([[0, 0],\n",
    "                      [0, h - 1],\n",
    "                      [w - 1, h - 1],\n",
    "                      [w - 1, 0]]).reshape(-1, 1, 2)\n",
    "    dst = cv2.perspectiveTransform(pts, M)\n",
    "\n",
    "    img2 = cv2.polylines(img2, [np.int32(dst)], True, 255, 3, cv2.LINE_AA)\n",
    "\n",
    "    h1, w1 = img1.shape\n",
    "    h2, w2 = img2.shape\n",
    "    nWidth = w1 + w2\n",
    "    nHeight = max(h1, h2)\n",
    "    hdif = int((h2 - h1) / 2)\n",
    "    newimg = np.zeros((nHeight, nWidth, 3), np.uint8)\n",
    "\n",
    "    for i in range(3):\n",
    "        newimg[hdif:hdif + h1, :w1, i] = img1\n",
    "        newimg[:h2, w1:w1 + w2, i] = img2\n",
    "\n",
    "    # Draw SIFT keypoint matches\n",
    "    for m in good:\n",
    "        pt1 = (int(kp1[m.queryIdx].pt[0]), int(kp1[m.queryIdx].pt[1] + hdif))\n",
    "        pt2 = (int(kp2[m.trainIdx].pt[0] + w1), int(kp2[m.trainIdx].pt[1]))\n",
    "        cv2.line(newimg, pt1, pt2, (255, 0, 0))\n",
    "\n",
    "    plt.imshow(newimg)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Not enough matches are found - %d/%d\" % (len(good), MIN_MATCH_COUNT))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
